---

layout: post
title: 应用管理平台kubevela
category: 架构
tags: Kubernetes
keywords:  Kubernetes kubevela

---

## 简介

* TOC
{:toc}

脉络：k8s yaml太多 ==> kustomize/helm（helm values.yaml太随意了） ==> 弄一个paas平台封装一下k8s==> 可扩展性（封装的标准化、可复用、IaC ） ==> OAM

## 为什么要用 KubeVela？

我个人之前的感受：paas自己写个发布系统对接k8s开发下就行了，最多就是后来灰度发布一类，k8s deployment不好使，出现了openkruise也就够了，oam那一套概念有点多余（就像k8s 刚出的时候 pod 多个容器 有点多余，不如marathon简单）。如果大家直接对接 k8s 做paas，那么各个公司paas开发人员的努力都是发散的，一家一个样，能力无法沉淀。有了oam 在应用层面先提一套标准，然后kubevela 确定核心细节，大家以 kubevela 为核心 复用能力 并进行简单的差异化，那么就有可能 把paas的能力沉淀下来。或者说，如果去卖一个paas 产品，如果没有kubevela 这套东西，根本就不可能商业化，case by case的为每个公司开发paas 产品，商业上根本走不通。

[为什么要用 KubeVela？](https://kubevela.io/zh/docs/)云原生技术的发展趋势正在朝着利用 Kubernetes 作为公共抽象层来实现高度一致的、跨云、跨环境的的应用交付而不断迈进。然而，尽管 Kubernetes 在统一底层基础架构细节方面表现出色，它并没有在**混合的分布式部署环境**之上提供应用层的软件交付模型和抽象。我们已经看到，这种缺乏统一上层抽象的软件交付过程，不仅降低了生产力、影响了用户体验，甚至还会导致生产中出现错误和故障。

然而，为现代微服务应用的交付过程建模是一个高度碎片化且充满挑战的事情。到目前为止，绝大多数试图解决上述问题的技术方案，要么过于简单以致于无法覆盖实际生产使用中的问题，要么过于复杂难以落地使用。云原生带来的基础设施能力爆发式增长也决定了**新一代的应用管理平台不能以硬编码的方式做能力的集成和 UI 的构建**，除了满足基础的功能和场景，平台本身的扩展能力成为了新时代应用管理平台的核心诉求。这就意味着平台不仅要简单易用，还要能够随着应用交付和管理的需求复杂度提升能够不断扩张，能够让开发者自助式的接入和使用，充分享受云原生生态的红利。

这也是 KubeVela 出现的核心价值：它既能够简化面向混合环境（多集群/多云/混合云/分布式云）的应用交付过程；同时又足够灵活可以随时满足业务不断高速变化所带来的迭代压力。它本身是一个面向混合交付环境同时又高可扩展的应用交付引擎，满足平台构建者的扩展和自建需求；同时又附加了一系列开箱即用的扩展组件，能够让开发者自助式的开发、交付云原生应用。


[深入解读：KubeVela 与 PaaS 有何不同？](https://developer.aliyun.com/article/779485?spm=a2c6h.14164896.0.0.4f7875ffH4j9hq)**kubevela 与 PaaS 最大的区别在可扩展性上**
1. PaaS 的用户体验虽好，但却往往是不可扩展的。要支持一个新的能力，都必须对 PaaS 进行一轮开发，而且由于先前的一些假设和设计，甚至很可能需要大规模的重构。举个例子，我有一个 PaaS 系统，它所有的应用都是通过 Deployment 来执行的，那么这个 PaaS 的发布、扩容等功能，也都会直接按照 Deployment 来进行实现。而现在，用户提出了原地升级的诉求，需要让这个 PaaS 再支持 CloneSet，那整套系统很可能就得掀翻重来。再到运维能力这一侧，这个问题会更加严重，比如现在这个 PaaS 支持的是蓝绿发布策略，那么它跟流量管理、监控系统等依赖之间，都是需要大量交互和集成的。而现在我们要让 PaaS 支持一个新的策略叫做“金丝雀”发布，那么所有的这些交互和执行逻辑基本全得重重构一遍，工作量是巨大的。
2. 相比之下，KubeVela 的目标从一开始就是利用整个 Kubernetes 生态作为自己的“插件中心”，并且“有意”把它的每一个内置能力都设计成独立的、可插拔的插件。这种高度可扩展的模型，背后其实有着精密的设计与实现。比如，KubeVela 如何确保某个完全独立的 Trait 一定能够绑定于某种 Workload Type？如何检查这些相互独立的 Trait 间是否存在冲突？这些挑战正是 Open Application Model（OAM）作为 KubeVela 模型层的起到的关键作用，一言以蔽之：OAM 是一个高度可扩展的应用定义与能力装配模型。
3. KubeVela 提倡的是一种面向未来的云原生平台架构，这种架构认为：
    1. 应用平台本身架构彻底模块化，其所有的能力都是可插拔的，而平台核心框架通过模型层提供标准化的能力封装与装配流程。
    2. 该流程能够无缝接入云原生生态中的任何应用管理能力，使得平台工程师完全专注于能力本身的研发和基于该模型的能力封装过程，使平台团队在为用户带来简单易用的平台层抽象的同时，快速、敏捷地响应用户千变万化的应用管理诉求。

不再配置漂移：除了扩展性和效率以外，许多围绕 IaC（Infrastructure-as-Code） 的工具都会引发生产环境和配置中心数据不一致的问题，业界称之为“配置漂移”，引起配置漂移的核心原因往往来自于生产环境的配置修改有多个来源、平台对配置的覆盖不完整等。KubeVela 通过一个 Application 对象涵盖了所有应用涉及的配置、并通过 Kubernetes 控制循环 来维护状态，并基于此始终面向终态维护配置的一致性、消除配置漂移的问题，且保留基于 IaC 模式的扩展性和灵活性。

## 使用

KubeVela 的核心是将应用部署所需的所有组件和各项运维动作，描述为一个统一的、与基础设施无关的**部署计划**，进而实现在混合环境中标准化和高效率的应用交付。每一个应用部署计划都由四个部分组成，分别是组件、运维能力、部署策略和工作流。其格式如下：

```yaml
apiVersion: core.oam.dev/v1beta1
kind: Application
metadata:
  name: <name>
spec:
  components:   # 定义一个应用包含的待交付制品（二进制、Docker 镜像、Helm Chart...）或云服务
    - name: <component name>
      type: <component type>
      properties:
        <parameter values>
      traits:   # 随时绑定给待部署组件的、模块化、可拔插的运维能力，比如：副本数调整（手动、自动）、数据持久化、 设置网关策略、自动设置 DNS解析等。 
        - type: <trait type>
          properties:
            <traits parameter values>
    - name: <component name>
      type: <component type>
      properties:
        <parameter values>    
  policies:     # 定义指定应用交付过程中的策略，比如多集群部署的差异化配置、资源放置策略、安全组策略、防火墙规则、SLO 目标
  - name: <policy name>
    type: <policy type>
    properties:
      <policy parameter values>
  workflow:     # 工作流由多个步骤组成，允许用户自定义应用在某个环境的交付过程。典型的工作流步骤包括人工审核、数据传递、多集群发布、通知等。
    - name: <step name>
      type: <step type>
      properties:
        <step parameter values>   
```

oam 单从格式看，**划分为components/traits/policies/workflow几个大类，每个类别包含 name/type/properties 字段**，使用时，更多是个性化指定properties。kebevela 作为中间层，将这些 运维参数 进行组装渲染，变成k8s的实际资源。

## 设计

[深入解读：KubeVela 与 PaaS 有何不同？](https://developer.aliyun.com/article/779485?spm=a2c6h.14164896.0.0.4f7875ffH4j9hq)在架构上，KubeVela 只有一个 controller （即ApplicationController）并且以插件的方式运行在 Kubernetes 之上，为 Kubernetes 带来了面向应用层的抽象，以及以此为基础的面向用户的使用界面，即Appfile。Appfile 乃至 KubeVela 运行机制背后的核心，则是其能力管理模型 Open Application Model (OAM) 。基于这个模型，KubeVela 为系统管理员提供了一套基于**注册与自发现的能力装配流程**，来接入 Kubernetes 生态中的任意能力到 KubeVela 中，从而以“一套核心框架搭配不同能力”的方式，适配各种使用场景（比如 AI PaaS，数据库 PaaS 等等）。

具体操作上，作为系统管理员或者平台开发者，上述能力装配流程允许他们把任意的 Kubernetes API 资源（含 CRD）以及对应的 Controller  作为“能力”一键注册到 KubeVela 中（即注册 XXDefinition），然后通过 CUE 模板语言将这些能力封装成用户可用的抽象（即成为 Appfile 中的一部分）。


### 从appfile 到 k8s object

任何应用交付需求 在kubevela 内核中实际上都会被表达为 一个基于cue 语言的有向无环图DAG。而Application 对象实际上只是这个DAG 面向用户侧的一种UI而已：一旦提交，它就会被kubevela 渲染成上述cue 代码然后使用kubernetes 来执行这个DAG。

[源码解读：KubeVela 是如何将 appfile 转换为 K8s 特定资源对象的](https://developer.aliyun.com/article/783169) PS：基于kubevela引入workflow之前的版本

![](/public/upload/kubernetes/kubevela_model.png)

### 从k8s object到 appfile

接下来，我们就来 Demo 一下如何将 kubewatch 这个社区中的告警机制直接插入到 KubeVela 中作为一个告警 Trait 来使用：
1. 将平台能力注册为 OAM 对象，首先，你需要确定 CRD 所表示的能力是对应一个 Workload Type 还是 Trait？这里的区别在于 **Workload Type 指的是如何运行你的代码。而 Trait 指的是如何运维、管理或者操作已经运行起来的代码实例**。而 KubeWatch 作为一种告警机制，自然作为 Trait 来使用的。这时候，我们就可以通过写一个 TraitDefinition yaml 来将它注册：

    ```yaml
    apiVersion: core.oam.dev/v1alpha2
    kind: TraitDefinition
    metadata:
      name: kubewatch
      annotations: 
        definition.oam.dev/description: "Add a watch for resource"
      spec:
        appliesToWorkloads: # trait 可以附加到指定的工作负载类型
          - "*"
        definitionRef:
          name: kubewatches.labs.bitnami.com
    ```

2. 编写 CUE template 来封装对外暴露接口。上一步完成，KubeVela 就已经注册完毕在 KubeVela 平台中可用了。但接下来我们还需要将它暴露给用户使用，所以需要定义这个能力对外的使用接口。实际上，大多数社区能力虽然很强大，但对于最终用户来都比较复杂，学习和上手非常困难。所以在 KubeVela 中，它允许平台管理员**对能力做进一步封装以便对用户暴露简单易用的使用接口**，在绝大多数场景下，这些使用接口往往只有几个参数就足够了。在能力封装这一步，KubeVela 选择了 CUE 模板语言，来连接用户界面和后端能力对象，并且天然就支持完全动态的模板绑定（即变更模板不需要重启或者重新部署系统）。下面就是 KubeWatch Trait 的模板例子：

    ```yaml
    ...
    spec:
      extension:
        template: |
          output: {
            apiVersion: "labs.bitnami.com/v1alpha1"
            kind: "kubewatch"
            spec: handler: webhook: url: parameter.webhook
          }
          parameter: {
            webhook: string
          }
      
    ```
3. 将这个模板放到 Definition 文件中并 ` kubectl apply -f` 到 Kubernetes 中，KubeVela 就会自动识别和处理相关输入。这时候，用户就可以直接在 Appfile 中声明使用刚加进来的能力了，比如发送告警信息到指定的 Slack channel：

    ```yaml 
    name: testapp
    services:
      testsvc: 
        type: webservice
        image: crccheck/hello-world
        port: 8000
        route: 
          domain: testsvc.example.com
        kubewatch:
          webhook: https://hooks.slack.com/<your-token>
    ```

可以看到，这个 kubewatch 的配置是我们通过三方扩展进来的一个新的能力，通过 KubeVela 平台**管理 Kubernetes 扩展能力**就是这么简单快速。有了 KubeVela，平台开发人员就可以简单快速地在 Kubernetes 上搭建起一个 PaaS，且能够将任何一个 Kubernetes 能力快速封装成面向最终用户的上层抽象。


## 与helm对比

[基于 KubeVela 与 Kubernetes 打造“无限能力”的开放 PaaS](https://mp.weixin.qq.com/s/frkBEwZSpNQstkwC6a4SUg)

### 将yaml拆分成模版与参数/配置

Helm 的抽象能力是基于 Go 的 template，而 KubeVela 对于抽象的实现是则基于 DCL（DataConfiguration Language）。

![](/public/upload/kubernetes/kubevela_cue.png)

首先用户填抽象数据，接着通过 CUE 的模板注册在 KubeVela 的服务端，然后用户填的数据和模板直接合并，最后生成一个完整的 K8sYAML。这种过程看起来和 Helm 的 Go template 以及 Helm 的 Values 很像，但是 CUE 有很多强大的功能，比如：

1. 专注于操纵数据，而不是写代码
2. 完全兼容 JSON
3. 简单直观：Schema 和 Value 语法一致

![](/public/upload/kubernetes/kubevela_cue_to_object.png)

以上方为例，首先定义 Workload， WorkloadDefinition 实际上就是一个模板，这个模板讲的是工作负载里一个 Deployment 模板，Deployment 下面是我们构建出来的参数 Parameter，它包含两个参数 Image 和 CMD；之后相当于把这个参数填到了 ③ 上面的工作负载中，它的类型 type=worker，也就是 ① 里面的 name=worker。

同时还有一些抽离出来的参数，就是底下的 Deployment 里面，比如 Sidecar，把它抽出来单独使用变成一个 Trait，Trait 里面可以写一些内容如 NAME 或 Image。如果不加 Trait，单独使用 Worker 也是完全可以的。同时这个 Trait 也可以给到其他基于 Deployment 或带有 “spec：template:spec:containers” 这种数组模式的工作负载使用（PS：**trait 原来是这么生效的**）。在 KubeVela 中，用户只要简单填写参数就会拿到这两个模板，然后在 KubeVela 中做 Merge，即 Patch 的合并，最后生成 Deployment。

||helm|kubevela|
|---|---|---|
|模版存在形式|yaml文件|xxDefinition|
|参数/配置存在形式|yaml文件|Application，划分为components/traits/policies/workflow几个大类，<br>每个类别包含 name/type/properties 字段|
|参数配置 + 模版如何翻译成k8s yaml|go template<br>简单的参数替换|cue，kubevela 也支持helm<br> 翻译由controller 进行，有时不单单是参数替换|
|部署|`helm install -f values.yaml`|`kubectl apply -f application.yaml`|
|能力复用|chart 应用商店|组件中心，应用市场|

### 应用模型——对参数/配置进行分类与规范

![](/public/upload/kubernetes/helm_template.png)

Helm 大家比较熟悉，它可以把不同的 YAML 文件写成模板，模板里面能抠出来一些 Values，然后填写一些 Values 的信息。但是这里 Helm 有一个问题，就是组装完后 Helm 整体会成为一个黑盒，用户无法获得 Helm 里整体的状态。
1. Helm 安装完后，它把这些抽象的能力变成K8s原始的资源，但这些资源是否安装成功，Helm 很难获得感知。
2. 同时用户如果想做统一的能力，如要把 Rollout 抽出来的概念变成公共的功能给 WebService 与 Knative Revision 使用，这种情况在 Helm 中无法实现（rollout 参数表达了回滚的镜像、个数等等，但针对不同对象，比如 对deployment 和 statefulset 做回滚差异很大，或者说最后生成的k8s yaml 差别很大），包括后期做统一的监控、统一的发布管理、统一的日志管理、统一的扩缩容等，Helm 均无法实现。但是在 KubeVela 中，基于 OAM 模型提供的公共标准，就可以实现一些公共的能力。

所以说，像**状态回流**和公共能力抽象是HELM无法做到的两点，但用KubeVela可以很容易做到。

![](/public/upload/kubernetes/oam_abstract.png)

抽象是构建云原生应用平台的基础，抽象本质上分为这三种类型：转换抽象（一变一）、组合抽象（一变多）和拆分抽象（多变一），以及抽象后的状态回流。

1. 组合抽象，以一个网络访问的服务为例，底下由 Deployment 与 Service 组合构建而成，用户希望拿到工作负载 WebService，这样一个组合的抽象可以给用户提供服务。
2. 拆分抽象，当我们在灰度发布时，K8s 生态经常会出现一些像 ArgoRollout 的发布能力，这些发布能力可能有个问题，就是把所有的概念全都糅杂在一起，有时用户在一开始使用时不关心的发布策略（如 Rollout）也在其中。“拆分抽像”的能力可以使用户在使用时把这些概念拆开来使用，在单独使用 Workload 部分时，应用也能正常运行，而不是说一定要填完 ArgoRollout。同时未来灰度发布时，用户如果希望有金丝雀的发布策略，KubeVela 也能将 Workload 与 Rollout 组装成 ArgoRollout。
3. 转换抽象，在K8s原来的概念中，有的部分用户并不关心，如 Deployment 里的 labelSelectors。KubeVela 可以做一层转换，就像 Knative Revision，去掉多余的参数，封装出干净的模型。

### appfile

除了构建抽象，如何让用户使用也是一个非常关键的问题。在这里 KubeVela 给大家提供一个用户层的视角，对于不关心 K8s 细细的业务应用研发者， KubeVela 提供了 AppFile 的概念。

![](/public/upload/kubernetes/kubevela_application.png)

如上图所示，Appfile 里会包含镜像的构建、镜像如何启动、端口是怎样的、资源有多少等信息。同时包含了一些 Trait 的参数，例如用户希望能够对外的访问提供一个域名、自动扩缩容的参数等，大家可以看到它是围绕应用展开的，没有一些多余的概念。同时它是一个文件，当用户在代码仓库里做统一变更时，体验效果非常好；同时它和应用环境没有关系，可以自动适配任意 K8s 集群与部署环境，并且具有很好的扩展能力。PS：其实单论把这个解析为 k8s yaml， helm 也可以，但是helm 仅仅是“翻译”为yaml，再进一步的工作比如状态回流等就很难做了。

## 实现

KubeVela 本身主要由如下几个部分组成:
1. 核心控制器 为整个系统提供核心控制逻辑，完成诸如编排应用和工作流、修订版本快照、垃圾回收等等基础逻辑
2. 模块化能力控制器 负责对 X-Definitions 对象进行注册和管理。
3. 插件控制器 负责注册和管理 KubeVela 运行所需要的第三方插件，比如 VelaUX、 Flux、Terraform 组件等等。
4. UI 控制台和 CLI UI 控制台服务于希望开箱即用的开发者用户，CLI 适用于集成 KubeVela 和终端管理的用户。

### 模块定义（Definition）

[模块定义（Definition）](https://kubevela.net/zh/docs/next/platform-engineers/oam/x-definition#%E6%A6%82%E8%BF%B0)

Application 有很多声明“类型的字段”，如组件类型、运维特征类型、应用策略类型、工作流节点类型等，这些类型实际上就是 OAM 模型的模块定义（X-Definition），这些模块在 KubeVela 中全部都是基于 CUE 的可编程模块。当前 OAM 模型支持的模块定义（X-Definition）包括组件定义（ComponentDefinition），运维特征定义（TraitDefinition）、应用策略定义（PolicyDefinition），工作流节点定义（WorkflowStepDefinition）等。

组件定义（ComponentDefinition）的设计目标是允许平台管理员将任何类型的可部署制品封装成待交付的“组件”。只要定义好之后，这种类型的组件就可以被用户在部署计划（Application）中引用、实例化并交付出去。

如何定义运维能力之间的冲突关系与协作关系？TraitDefinition 中包含 conflictsWith 字段，用来描述该trait 与哪些trait 冲突。运维特征定义的格式和字段作用如下：

```yaml
apiVersion: core.oam.dev/v1beta1
kind: TraitDefinition
metadata:
  name: <运维特征定义名称>
  annotations:
    definition.oam.dev/description: <功能描述说明>
spec:
  definition:
    apiVersion: <运维能力对应的 Kubernetes 资源组>
    kind: <运维能力对应的 Kubernetes 资源类型>
  workloadRefPath: <运维能力中对于工作负载对象的引用字段路径>
  podDisruptive: <运维能力的参数更新会不会引起底层资源（pod）重启>
  manageWorkload: <是否由该运维特征管理工作负载>
  skipRevisionAffect: <该运维特征是否不计入版本变化的计算>
  appliesToWorkloads:
  - <运维特征能够适配的工作负载名称>
  conflictsWith:
  - <与该运维特征冲突的其他运维特征名称>
```
### 自定义插件

如何基于 CUE 语言定义出功能强大的“能力模块”，然后把这些模块安装到 KubeVela 中？ [自定义插件](https://kubevela.net/zh/docs/next/platform-engineers/addon/intro)

## 应用

[基于 KubeVela 的机器学习实践](https://mp.weixin.qq.com/s/pTYK_WsdSwwiv7_Dzkxh_w) 未细读，好神奇

[Kubevela 下的多集群应用](https://mp.weixin.qq.com/s/IbMTP5q-522oGpE1rRF1zw)





