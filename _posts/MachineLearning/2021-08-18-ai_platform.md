---

layout: post
title: AI云平台
category: 架构
tags: MachineLearning
keywords:  ai platform

---

## 简介

* TOC
{:toc}

《人工智能云平台原理、设计与应用》近年来涌现了很多智能算法，这些算法需要软件的支撑，没有软件的支撑，理论很难与应用相结合，新硬件也很难为应用提速，所以巨头们推出了TensorFlow、Pytorch等开源框架，然而这些框架不足以支撑人工智能全流程生产化应用，它们仅面向个人开发者和研究人员，管理少数计算设备资源，无法在云计算资源上提供面向多租户的智能应用全流程服务。欠缺诸如海量样本数据管理与共享存储、集群管理、任务调度、快速训练与部署、运行时监控等能力，缺乏人工智能生产流程的抽象、定义和规范，导致用户形成生产力的成本过高。

海量数据标注 + 大规模计算 + 工程化（python或c++）=AI系统，也被称为MLaaS/MLOps。

![](/public/upload/machine/ai_develop_progress.png)

AI 平台可能是云原生技术栈上最具"可玩性"的一种场景。种类繁多的异构资源和通讯形式、调度策略、常规业务不需要的拓扑感知、花式任务编排、数据密集型有状态应用、天然离/在线混部。

## 《MLOps实践》

我们开发ML模型依赖于几个要素，如数据、算法或参数，在实验过程中，这些要素会随着时间的推移而改变，从而生成不同的版本。创建数据和参数版本镜像可以帮助我们跟踪不同的版本，但版本控制有其自身的成本。世面上有很多书讲算法原理、如何训练ML模型，也有很多书讲如何构建软件项目，但很少有书把这两个世界融合起来，对于如何构建由ML驱动实际应用的项目工程方面，如数据收集、存储、模型部署、管理以及监控运维等方面的书却很少见。

ML 是一个通过算法和统计模型从数据中学习知识的学科，当我们遇到的问题可以用一套可管理的确定性规则（且随着数据变化并不需要变更规则）来解决时，这类问题便不需要ML。

DevOps依靠工具、自动化和工作流程来抽象软件工程的复杂性，让开发人员专注于需要解决的实际问题，在软件开发领域已经基本成为标配，那为什么这套方法论或经验不能直接应用到ML领域呢？其原因在于，ML的**跨领域特性**延伸出了新的维度，比如**增加了一个额外的数据维度**
1. 对于传统软件，几乎可以即时体现代码变化对结果的影响，但在ML中，想到看到代码变化对结果的影响需要重新训练模型
2. 对于传统软件，一个版本的代码产生一个版本的软件，在版本控制系统的辅助下，我们可以在任何时候创建应用程序的任意变体。在ML中，**开发的结果不是代码而是模型**，而这个模型又是由创建和训练模型的代码版本及其所使用的数据产生。代码和数据分别处在两个平行的平面上，它们之间共享时间维度，但在所有其它方面都是独立的。
3. 在ML 中，不仅要保存不同版本的代码，还需要一个地方来保存不同版本的数据和模型工件，和涉及的元数据信息。与代码不同，模型性能会随着时间的推移而衰退，这就需要监控。一旦发现预测准确率下降， 就需要新的数据重新训练模型，**训练永远不会结束**，即ML的迭代属性。
ML的迭代属性意味着， 如果没有完备的自动更新流程，想要通过手动的方式来反映这些变化需要大量的工作，这是一个系统工程。

|实践|DevOps|DataOps|MLOps|
|---|---|---|---|
|版本控制|代码版本化|数据版本化|代码版本化<br/>数据版本化<br/>模型版本化|
|管道|n/a|数据处理管道<br>ETL|训练管道<br>服务管道|
|行为验证|单元测试|单元测试|模型验证和测试|
|数据验证|n/a|数据格式及业务逻辑验证|统计验证|
|CI/CD|将代码部署至生产环境|将数据处理管道部署至生产环境|部署代码及训练管道至生产环境|
|监控|SLO|SLO|SLO<br>异常监控<br>统计监控|

## 业界实践
### 虎牙

[互动直播场景下的AI基础设施建设](https://time.geekbang.org/qconplus/detail/100059720)

手动时代

![](/public/upload/machine/huya_ai_manual.png)

AI平台的定位：面向算法工程师，围绕AI 模型的全生命周期去提供一个一站式的机器学习服务平台。

![](/public/upload/machine/huya_platform_1.png)
![](/public/upload/machine/huya_platform_2.png)


### 腾讯

[高性能深度学习平台建设与解决业务问题实践](https://time.geekbang.org/qconplus/detail/100059719)构建公司统一的大规模算力，方便好用的提供GPU

![](/public/upload/machine/tecent_platform_2.png)

### 阿里

[KubeDL 加入 CNCF Sandbox，加速 AI 产业云原生化](https://mp.weixin.qq.com/s/7SUhnW4cnk_3G9Q7lIytcA)

从算法工程师着手设计第一层神经网络结构，到最终上线服务于真实的应用场景，除 AI 算法的研发外还需要大量基础架构层面的系统支持，包括数据收集和清理、分布式训练引擎、资源调度与编排、模型管理，推理服务调优，可观测等。众多系统组件的协同组成了完整的机器学习流水线。

具体的说
1. 数据抽取组件->实现样本数据筛选
2. 画像组件->实现样本数据与画像字段的关联
3. 特征组件->实现画像数据到特征数据格式的转换
4. 切分组件->实现样本抽样
5. 深度组件->实现用户自定义模型训练
6. 预测组件->验证模型指标
7. 部署组件->模型部署上线
8. 串联上述所有组件的**工作流组件**，以支持算法工程师 模型训练部署的整个过程。PS: 具体实现上设计到 自己实现或使用工作流引擎。
自动化能自动的，加速能加速的，减少模型耗时，加快算法工程师的产出效率，并以此为前提提高资源利用率。 

[摆脱 AI 生产“小作坊”：如何基于 Kubernetes 构建云原生 AI 平台](https://mp.weixin.qq.com/s/yGc44Q0qseDG7zy0-PC8gg)在初期，用户利用 Kubernetes，Kubeflow，nvidia-docker 可以快速搭建 GPU 集群，以标准接口访问存储服务，自动实现 AI 作业调度和 GPU 资源分配，训练好的模型可以部署在集群中，这样基本实现了 AI 开发和生产流程。紧接着，用户对生产效率有了更高要求，也遇到更多问题。比如 GPU 利用率低，分布式训练扩展性差，作业无法弹性伸缩，训练数据访问慢，缺少数据集、模型和任务管理，无法方便获取实时日志、监控、可视化，模型发布缺乏质量和性能验证，上线后缺少服务化运维和治理手段，Kubernetes 和容器使用门槛高，用户体验不符合数据科学家的使用习惯，团队协作和共享困难，经常出现资源争抢，甚至数据安全问题等等。从根本上解决这些问题，AI 生产环境必然要从“单打独斗的小作坊”模式，向“资源池化+AI 工程平台化+多角色协作”模式升级。我们将云原生 AI 领域聚焦在两个核心场景：持续优化异构资源效率，和高效运行 AI 等异构工作负载。
1. 优化异构资源效率
2. 运行 AI 等异构工作负载，兼容 Tensorflow，Pytorch，Horovod，ONNX，Spark，Flink 等主流或者用户自有的各种计算引擎和运行时，统一运行各类异构工作负载流程，统一管理作业生命周期，统一调度任务工作流，保证任务规模和性能。一方面不断提升运行任务的性价比，另一方面持续改善开发运维体验和工程效率。

![](/public/upload/machine/ai_platform_tech.png)

用户体验：对于数据科学家和算法工程师开发训练 AI 模型来说，Kubernetes 的语法和操作却是一种“负担”。他们更习惯在 Jupyter Notebook 等 IDE 中调试代码，使用命令行或者 Web 界面提交、管理训练任务。任务运行时的日志、监控、存储接入、GPU 资源分配和集群维护，最好都是内置的能力，使用工具就可以简单操作。因此要提供命令行工具/SDK/运维大盘/开发控制台来满足用户的各种需要。 [AI 作业生命周期管理（Arena）](https://mp.weixin.qq.com/s/yGc44Q0qseDG7zy0-PC8gg)

### vivo

训练平台 + 推理平台 + 容器平台（日常维护cli ==> 白屏化）

[一站式机器学习平台在 vivo AI 的实践](https://www.infoq.cn/article/thlkstomylrgxl2hzm8w)

算力的易用性
1. 分布式训练
2. 交互式调试
3. 容量托管
4. 训练sdk

算力的灵活调度
1. 基于容器的资源调度
2. 在离线统一资源池
3. 混合云 [vivo AI 计算平台的 ACK 混合云实践](https://mp.weixin.qq.com/s/O7y6kr01Au-T8M0kah7D9w)
4. 基于GPU 拓扑的调度
 
算力的高效利用
1. 资源分配：弹性伸缩、算力超卖（多个容器使用一张卡，GPU隔离）
2. 资源使用：训练/推理加速，训练容错
3. 弹性训练 [vivo AI 计算平台弹性分布式训练的探索和实践](https://www.infoq.cn/article/EhRjlkwxs6C6cT4cHzlt)
4. 训练性能剖析
5. GPU 远程调用
6. 数据编排和加速

[vivo推荐中台升级路：机器成本节约75%，迭代周期低至分钟级](https://mp.weixin.qq.com/s/fpmepb75j_Qr0UlXR6YnQg)玲珑·推荐中台主要为数据及算法工程师提供从算法策略到 A/B 实验的工程架构解决方案、通用的特征服务和样本生产服务、模型的离线训练到上线部署全生命周期管理、高性能推理等能力。玲珑·推荐中台包含四大模块：推荐中心、特征中心、模型中心、端云协同推荐。

![](/public/upload/machine/vivo_ai_platform.png)

具体一点

![](/public/upload/machine/vivo_ai_platform_overview.png)


### 腾讯

[腾讯般若系统](https://mp.weixin.qq.com/s/NISDTSjrHCRSHbjkH5b-Bg)

### 美团

[美团外卖特征平台的建设与实践](https://mp.weixin.qq.com/s/CWY7RQcfidkvAAQCI5kRKg)

![](/public/upload/machine/meituan_ai.png)

## 基础设施

### 工作流

[美团外卖特征平台的建设与实践](https://mp.weixin.qq.com/s/CWY7RQcfidkvAAQCI5kRKg)平台化建设最重要的流程之一是“如何进行流程抽象”，业界有一些机器学习平台的做法是平台提供较细粒度的组件，让用户自行选择组件、配置依赖关系，最终生成一张样本构建的DAG图。对于用户而言，这样看似是提高了流程编排的自由度，但深入了解算法同学实际工作场景后发现，算法模型迭代过程中，大部分的样本生产流程都比较固定，反而让用户每次都去找组件、配组件属性、指定关系依赖这样的操作，会给算法同学带来额外的负担，所以我们尝试了一种新的思路来优化这个问题：模板化 + 配置化，即平台提供一个基准的模板流程，该流程中的每一个节点都抽象为一个或一类组件，用户基于该模板，通过简单配置即可生成自己样本构建流程。PS：就是多提供了一个模板？

[大规模运行 Apache Airflow 的经验和教训](https://mp.weixin.qq.com/s/KEAHAiqV4iqdO9hUW8fu6w)Apache Airflow 是一个能够开发、调度和监控工作流的编排平台。未细读

[深入探索云原生流水线的架构设计](https://mp.weixin.qq.com/s/P57XYUnxE2gxA8VIBzX-TQ)
1. 在 Pipeline 中，我们对一个任务执行的抽象是 ActionExecutor。一个执行器只要实现单个任务的创建、启动、更新、状态查询、删除等基础方法，就可以注册成为一个 ActionExecutor。
    1. Engine 层负责流水线的推进，包括：Queue Manager 队列管理器，支持队列内工作流的优先级动态调整、资源检查、依赖检查等。Dispatcher 任务分发器，用于将满足出队条件的流水线分发给合适的 Worker 进行推进。Reconciler 协调器，负责将一条完整的流水线解析为 DAG 结构后进行推进，直至终态。
    2. 模块内部使用插件机制，对接各种任务运行时。
2. 在一条流水线中，节点间除了有依赖顺序之外，一定会有数据传递的需求。上下文传递，后置任务可以引用前置任务的“值”和“文件”
3. Pipeline 之所以好用，是因为它提供了灵活一致的流程编排能力，并且可以很方便地对接其他**单任务执行平台**，这个平台本身不需要有流程编排的能力。调度时，根据任务类型智能调度到对应的任务执行器上，包括 K8sJob、Metronome Job、Flink Job、Spark Job 等等。
4. 这里简单列举一些比较常见的功能特性：
    1. 配置即代码
    2. 扩展市场丰富
    3. 可视化编辑
    4. 支持嵌套流水线
    5. 灵活的执行策略，支持 OnPush / OnMerge 等触发策略
    6. 支持工作流优先队列
    7. 多维度的重试机制
    8. 定时流水线及定时补偿功能
    9. 动态配置，支持“值”和“文件”两种类型，均支持加密存储，确保数据安全性
    10. 上下文传递，后置任务可以引用前置任务的“值”和“文件”
    11. 开放的 OpenAPI 接口，方便第三方系统快速接入



## 其它


深度学习平台的搭建，将遇到诸多挑战，主要体现在以下方面：

1. 数据管理自动化。在深度学习的业务场景中，从业人员会花费大量的时间获取和转换建立模型需要的数据。数据处理过程中还将产生新的数据，这些数据不单单应用于本次训练，很可能用于后续推理过程。并且新 生成的数据不需要传给数据源，而是希望放置在新的存储空间。这需要基础平台提供可扩展的存储系统。PS： 手动命令行、页面、代码上传、下载，pod 随时可以访问，分布式训练任务多pod 之间也要共享一些临时的存储文件。[ AI 数据编排与加速（Fluid）](https://mp.weixin.qq.com/s/yGc44Q0qseDG7zy0-PC8gg)
2. 资源的有效利用。深度学习相关的应用是资源密集型，资源使用波动大，存在峰值和谷值。在应用开始运行的时候，快速获取计算资源；在应用结束后，回收不适用的计算资源对于资源利用率的提升相当重要。数据处理、模型训练和推理所使用的计算资源类型和资源占用时间有所不同，这就需要计算平台提供弹性的资源供应机制。
3. 屏蔽底层技术的复杂性

如何跟公有云协同 [vivo AI 计算平台的 ACK 混合云实践](https://mp.weixin.qq.com/s/O7y6kr01Au-T8M0kah7D9w)


AI 中台具备六大能力。
1. 统一的存储空间，支持多数据源导入。
2. Pipeline 可视化工作流管理与执行，支持数据科学家从数据建模阶段开始的可视化管理，节省成本，快速体现数据科学家的价值。[深入探索云原生流水线的架构设计](https://mp.weixin.qq.com/s/P57XYUnxE2gxA8VIBzX-TQ)
3. 基于容器的计算资源分配和软件库安装，支持 TensorFlow、PyTorch 等各种框架。
4. 支持 GPU、TPU、CPU 框架和基于异构计算的模型管理。
5. 模型管理，支持新手快速上手，无需通过自己实现原始算法，只需要理解算法原理就可以通过调参实现。
6. AI Serving，模型一键封装为 API，一键部署。


