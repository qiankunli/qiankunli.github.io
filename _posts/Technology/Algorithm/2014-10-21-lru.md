---
layout: post
title: LRU实现
category: 技术
tags: Algorithm
keywords: 算法 LRU
---


## 前言 ##

近日面试有一个算法题，设计一个数据结构实现LRU。当时发挥的并不好，现在来仔细讲讲这个问题。写这篇文章虽然是马后炮，但整理和推理的过程还是很有乐趣的。

## 问题 ##

Design and implement a data structure for Least Recently Used (LRU) cache. It should support the following operations: get and set.

1. get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1

2. set(key, value) - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.

## 解决思路 ##

首先要分析都有哪些操作，针对我们提供的数据结构，分析每个操作花费的时间。先提出一个最笨的方法，然后不断优化。说实话，算法方面我不是特别擅长，逐渐逼近最优值，是个不错的办法。首先做一个初步的判断：

get(key)时，有两个操作：

1. 我们要尽快判断key是否在数据结构中，很自然地，我们可以使用哈希表，负责维护key和存放key节点位置的映射，复杂度为O(1)。
 
2. 我们要记录数据被访问的优先次序，有两个方法：
        
  2.1. 为每个数据记录一个对应的值（最后一次访问时间，或者某个整数值）
  2.2. 通过调整数据的位置来维护数据被访问的次序。
 
 很明显，第一个方法并不可取，因为如果cache较大时，我们确定谁最长时间没有被访问，需要比较整个数据结构，耗费较大。如果采用第二个数据结构，则要求该数据结构能够非常方便的移动元素，很自然的，可以想到链表。 
    

## 单链表+哈希表 ##

好，我们先用一个简单的单链表，分析每个操作的耗费：

get(key)时

1. 判断key是否在链表中，使用hashtable，复杂度为O(1)
2. 设定开头位置存放最近访问的，链表尾部存放最久未访问的。
  
  2.1. 如果key不在链表中，则将key插入到链表头部，此处调用set(key)
 
  2.2. 如果key在链表中，则将key节点移动到链表头部。此处问题出现，我们虽然可以知道key节点的指针，但无法直接得到key节点上一个节点的指针（没有上一个节点指针，删除key节点后，key前后节点无法连接），也即需要从头结点开始遍历才能得到，复杂度为O(n)。（这是个小细节，一般很难注意到）

so，问题很明显了，我们需要一个双联表

## 双链表+哈希表 ##

分析每个操作的耗费：

get(key)时

1. 判断key是否在链表中，使用hashtable，复杂度为O(1)
2. 设定开头位置存放最近访问的，链表尾部存放最久未访问的。
  
  2.1. 如果key不在链表中，则将key插入到链表头部，此处调用set(key)
 
  2.2. 如果key在链表中，则将key节点移动到链表头部(先删除，再插入到头部)，复杂度为O(1)

set(key)时

1. 如果cache还有空间，则直接插入
2. 如果cache已满，则删除最后一个元素，再插入key。为提高删除最后一个元素的效率，可以维护一个指针，指向最后一个元素。此时，时间复杂度为O(1)。

## 其它方法 ##

在搜集该类资料的过程中，还有提到双队列等其它方法的。说实话，这就是算法工程师研究的问题了，按以上的推理过程，实在是不好直接串联起来，应该是对这个算法有长期思索的人提出来的。

## 小结 ##
如果问数组和单链表的优缺点，我们都会背：数组方便随机访问，链表方便插入和删除。

其实，所谓的方便插入和删除数据，是说链表插入和删除数据，数据不用“挪窝”，而不是说操作效率就没有提升的空间。此处，使用hashtable结构后，链表的随机访问已不成问题，插入和删除数据的效率上升为"主要矛盾"（删除时还是要从头遍历链表），这个是需要意识到的。