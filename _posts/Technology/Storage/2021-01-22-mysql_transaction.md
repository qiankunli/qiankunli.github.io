---

layout: post
title: mysql 事务
category: 技术
tags: Storage
keywords: Redis

---

## 前言

* TOC
{:toc}


《软件架构设计》通俗的讲，事务就是一个“代码块”，这个代码块要么不执行，要么全部执行。事务要操作数据（数据库里面的表），事务与事务之间会存在并发冲突，就好比在多线程编程中，多个线程操作同一份儿数据，存在线程间的并发冲突是一个道理。 

[一个线上SQL死锁异常分析：深入了解事务和锁](https://mp.weixin.qq.com/s/b7Qnzh1EIM4wbExwmIkJyA)我们在业务实现时，经常需要保证某一批SQL能够具备ACID特性，如果没有事务，在应用里自己保证将会变得非常复杂，InnoDB引擎引入事务机制，极大简化了我们在此方面的编程模型。PS：**事务支持是在引擎层实现的**。

ACID的实现机制是什么？
1. 原子性（Atomicity）：事务内SQL要么同时成功要么同时失败 ，基于UndoLog实现。
2. 一致性（Consistency）：系统从一个正确态转移到另一个正确态，由应用通过AID来保证，并非数据库的责任。
3. 隔离性（Isolation）：控制事务并发执行时数据的可见性，基于锁和MVCC实现。
4. 持久性（Durability）：提交后一定存储成功不会丢失，基于RedoLog实现。

## 事务的原子性和持久性——redo/undo log

![](/public/upload/storage/run_sql.png)

宕机恢复后（redo log undo log 貌似都是从宕机恢复的视角来说的）

1. InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。并不关心事务性，提交的事务和未提交的事务都被重放了，从而**让数据库”原封不动“的回到宕机前的状态**。
2. 重放完成后，再把未完成的事务找出来，逐一利用undo log进行逻辑上的“回滚”。 undo log 记录了sql 的反操作，所谓回滚即 执行反操作sql

可以看出，redo log 不保证事务原子性， 只是保证了持久性， 不管提交未提交的事务都会进入redo log。

**redo log和undo log所做的一切都是为了提高 数据本身的IO效率**，已提交事务和未提交事务的数据 可以随意立即/延迟写入磁盘。代价是，事务提交时，redo log必须写入到磁盘，**数据随机写转换为日志数据顺序写**。PS，随机写优化为顺序写，也是一种重要的架构优化方法。 

![](/public/upload/data/mysql_commit_transaction.jpg)

### redolog

1. 同步写改为异步写：数据写磁盘一般是随机的，单次较慢，也不允许频繁写入。数据写入一般先保存在内存中，然后定期将内存数据写入到磁盘
3. 用Write-Ahead log/redo log 解决异步写在宕机场景下的数据丢失问题

![](/public/upload/data/mysql_transaction_redo_log.jpg)

应用层所说的事务都是”逻辑事务“，以上图为例，在逻辑层面事务是三条sql语句，涉及两张表。在物理层面，可能是修改了两个Page，修改每个page 产生一部分日志，生成一个LSN，存储到Redo log 的Block 里。不同事务的日志在 redo log 中是交叉存在的。

redo log buffer 是一块内存，用来暂存 redo 日志，事务commit时真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字）

从逻辑上来说，日志就是一个无限延长的字节流，从数据库启动开始，日志便源源不断的追加，直到结束。但从物理上来看，日志不可能是一个永不结束的字节流， 磁盘是块设备，磁盘的读取和写入都不是按照一个个字节来处理的，日志文件不可能无限膨胀，过了一定时间，之前的历史日志就不需要了。

在支付业务中，有一个用户账户表，还会有一个用户账户临时表，更新用户账户的金额数据时，经常先在临时表中先插入一条日志，因为只有插入操作，自然没有并发问题，然后再去更新用户账户。此时，临时表的作用就类似于redo日志。

### undo log

InnoDb为支持回滚和MVCC，需要**旧数据存档**，UndoLog就负责存储这些数据，当更新BufferPool数据前，先将之前数据存入UndoLog。

undo log 不是log，而是数据，每个事务在修改记录之前，都会先把该记录拷贝出来一份，存在undo log里，也就是copyOnWrite。也正因为每条记录都有多个版本，才很容易实现隔离性。事务提交后，没用其它事务引用的“历史版本/undo log”就可以删除了。PS：跟cpu 缓存导致一条内存数据多个cpu 副本异曲同工

InnoDB将Undo Log看作数据，因此记录Undo Log的操作也会记录到redo log中，包含Undo Log操作的Redo Log，看起来是这样的：

```
记录1: <trx1, Undo log insert <undo_insert …>>
记录2: <trx1, insert …>
记录3: <trx2, Undo log insert <undo_update …>>
记录4: <trx2, update …>
记录5: <trx3, Undo log insert <undo_delete …>>
记录6: <trx3, delete …>
```

## 事务的隔离性——MVCC与锁
	
为了控制事务并发时的数据安全，在不同隔离级别下会通过不同的协同机制进行处理。传统隔离机制，完全由锁(LBCC)来处理，但是这样只能满足**读读并发**，会对性能造成很大影响，故而出现了支持**读写并发**的MVCC。

**mysql 作为一个数据库，其实就是sql的 解释执行器，这一点和jvm 作为字节码的解释执行器是一样一样的。**但跟java语言层面的并发安全又有所不同，java语言层面就两个安全级别：安全，不安全。目的是为了保证一致性，但绝对的一致性要损失性能，因此允许哪些异常（少加一点锁或者允许读取老数据）便产生了一致性强弱的区别。PS：**就像主从同步一样，读可以读从库（从库类似于 MVCC 的副本，很多业务可以接受一点不一致）**，写则必须去主库写。 追求绝对的并发安全会导致性能的下降。为了提高性能，可以降低并发控制”强度“，从读写的角度提出了一个隔离性的概念来描述并发安全的程度。

### 事务和锁的关系

db 锁并不直接对 开发暴露，锁用于支持实现不同的事务的隔离性强度（有讨论价值的主要是RR和RC），加锁情况太多，容易晕。举个例子感受下事务和锁的关系
1. 聚簇索引（查询命中，存在id=15） `UPDATE students SET score = 100 WHERE id = 15;`，RC、RR都是对聚簇索引加X锁。未命中（存在id=16），RC不加锁，RR在16之前和之后的范围里加GAP锁。
2. 二级唯一索引（查询命中，存在no=`S0003`），`UPDATE students SET score = 100 WHERE no = 'S0003'`，RC、RR会对二级和聚簇索引都加X锁（防止其他事务通过聚簇改数据）。未命中，RC不加锁，RR只在二级索引加GAP锁。

### MVCC 为数据提供多个副本

《MySQL实战45讲》一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？

1. `begin/start transaction` 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 `start transaction with consistent snapshot` 这个命令。
2. 在 MySQL 里，有两个“视图”的概念
    1. 一个是 view。它是一个用查询语句定义的虚拟表，创建视图的语法是 `create view …` ，而它的查询方法与表一样。
    2. 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。它**没有物理结构**，作用是事务执行期间用来定义“我能看到什么数据”。
3. 在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。如果一个库有 100G，那么我启动一个事务，MySQL 就要拷贝 100G 的数据出来，这个过程得多慢啊。实际上，我们并不需要拷贝出这 100G 的数据。
4. InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id（trx_id 即操作 row 的事务id）。一行记录的 多个版本并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的

## 可重复读——可以读到什么数据

按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。在实现上， InnoDB 为每个事务构造了一个**数组**，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。

![](/public/upload/storage/storage_water_level.png)

**数据版本的可见性规则，就是基于数据的 row trx_id 和这个高低水位/事务视图（每个事务的高低水位都不同）对比结果得到的**。对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：
1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据对当前事务是可见的；
2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是当前事务肯定不可见的；
3. 如果落在黄色部分，那就包括两种情况：a 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，对当前事务不可见； b 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，对当前事务可见。

有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，生成的版本一定属于上面的 2 或者 3(a) 的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。**InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力**（PS：有点copy on write的feel）。一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
1. 版本未提交，不可见；
2. 版本已提交，但是是在视图创建后提交的，不可见；
3. 版本已提交，而且是在视图创建前提交的，可见。

### 可重复读——更新逻辑

当事务要去更新数据的时候，就不能再在历史版本上更新了，否则其它事务的更新就丢失了。

update 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）：必须要读最新版本，而且必须加锁。当前读的规则，就是要能读到所有已经提交的记录的最新值。

如果当前记录的行锁被其他事务占用的话，就需要进入锁等待。根据两阶段锁协议，其他事务提交才会释放锁，因此可以读到其他事务提交后的row。

除了 update 语句外，select 语句如果加锁，也是当前读

```sh
# 加读锁
mysql> select k from t where id=1 lock in share mode;
# 加写锁
mysql> select k from t where id=1 for update;
```
### mvcc 实现

postgresql、mysql、tidb对 mvcc 有着不同的实现方案。

[TiKV 事务模型概览，Google Spanner 开源实现](https://pingcap.com/blog-cn/tidb-transaction-model/)MVCC层暴露给上层的接口行为定义：

    MVCCGet(key, version), 返回某 key 小于等于 version 的最大版本的值
    MVCCScan(startKey, endKey, limit, version), 返回 [startKey, endKey) 区间内的 key 小于等于 version 的最大版本的键和值，上限 limit 个
    MVCCPut(key, value, version) 插入某个键值对，如果 version 已经存在，则覆盖它。上层事务系统有责任维护自增version来避免read-modify-write
    MVCCDelete(key, version) 删除某个特定版本的键值对, 这个需要与上层的事务删除接口区分，只有 GC 模块可以调用这个接口

[从CPU Cache出发彻底弄懂volatile/synchronized/cas机制](https://juejin.im/post/5c6b99e66fb9a049d51a1094)cpu 硬件因为多级缓存的缘故，一般的cpu 指令操作的是local cache，**对于同一个数据，因为local cache 存在天然的有了多 verison**。

各CPU都会通过总线嗅探来监视其他CPU，一旦某个CPU对自己Cache中缓存的共享变量做了修改（能做修改的前提是共享变量所在的缓存行的状态不是无效的），那么就会导致其他缓存了该共享变量的CPU将该变量所在的Cache Line置为无效状态，在下次CPU访问无效状态的缓存行时会首先要求对共享变量做了修改的CPU将修改从Cache写回主存，然后自己再从主存中将最新的共享变量读到自己的缓存行中。

**缓存一致性协议**通过缓存锁定来保证CPU修改缓存行中的共享变量并通知其他CPU将对应缓存行置为无效这一操作的原子性，即当某个CPU修改位于自己缓存中的共享变量时会禁止其他也缓存了该共享变量的CPU访问自己缓存中的对应缓存行，并在缓存锁定结束前通知这些CPU将对应缓存行置为无效状态。在缓存锁定出现之前，是通过总线锁定来实现CPU之间的同步的，即CPU在回写主存时会锁定总线不让其他CPU访问主存，但是这种机制开销较大

## 读提交

读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：
1. 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图（高低水位），之后事务里的其他查询都共用这个一致性视图；对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
2. 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图（高低水位）。对于读提交，查询只承认在语句启动前就已经提交完成的数据；

## 一致性

[理解事务 - MySQL 事务处理机制](https://juejin.im/entry/58f08b4cda2f60005d225a8e)在事务T开始时，此时数据库有一种状态，这个状态是所有的MySQL对象处于一致的状态，例如数据库完整性约束正确，日志状态一致等，当事务T提交后，这时数据库又有了一个新的状态，不同的数据，不同的索引，不同的日志等，但此时，**约束，数据，索引，日志（binlog/redo/undo log）等MySQL各种对象还是要保持一致性（正确性）。** 这就是 从一个一致性的状态，变到另一个一致性的状态。也就是事务执行后，并没有破坏数据库的完整性约束。有分布式一致性，其实一致性问题分布式和单机都有。

[条分缕析分布式：到底什么是一致性？](https://mp.weixin.qq.com/s/qnvl_msvw0XL7hFezo2F4w)ACID中的一致性，是个很偏应用层的概念。原子性、隔离性和持久性，都是数据库本身所提供的技术特性；而一致性，则是由特定的业务场景规定的。要真正做到ACID中的一致性，它是要依赖数据库的原子性和隔离性的（应对错误和并发）。但是，就算数据库提供了所有你所需要的技术特性，也不一定能保证ACID的一致性。这还取决于你在应用层对于事务本身的实现逻辑是否正确无误。ACID中的一致性，甚至跟分布式都没什么直接关系。它跟分布式的唯一关联在于，在分布式环境下，它所依赖的数据库原子性和隔离性更难实现。

## 日志点分析

[MySQL checkpoint深入分析](http://www.cnblogs.com/geaozhang/p/7341333.html)

[MySQL · 引擎特性 · InnoDB redo log漫游](http://mysql.taobao.org/monthly/2015/05/01/)

![](/public/upload/architecture/inner_mysql_1.png)

为了防止数据丢失，采用WAL，事务（具体应该是数据增删改操作）提交时，先写重做日志，再修改页。LSN(log sequence number) 用于记录日志序号，它是一个不断递增的 unsigned long类型整数。**因为写redo log是第一个要做的事儿，因此可以用lsn来做一些标记。**在 InnoDB 的日志系统中，LSN 无处不在，它既用于表示修改脏页时的日志序号，也用于记录checkpoint，通过LSN，可以具体的定位到其在redo log文件中的位置。

为了管理脏页，在 Buffer Pool 的每个instance上都维持了一个flush list，flush list 上的 page 按照修改这些 page 的LSN号进行排序。猜测：脏页刷新到磁盘时，应该也是按lsn顺序来的，不会存在较大lsn已经刷盘，而较小lsn未刷盘的情况。


|编号|lsn的某个状态值|说明|本阶段的lsn redo log所在位置|本阶段的lsn对应页的内存和硬盘一致性状态|备注|
|---|---|---|---|---|---|
|1|Log sequence number|最新日志号|||
|2|Log flushed up to |日志刷盘量|2~1:内存|2~1:不一致||
|3|Pages flushed up to|脏页刷盘量|3~2:硬盘|3~2:不一致|没找到地方显式存在|
|4|Last checkpoint at |上一次检查点的位置|4~3:硬盘|4~3:一致，此时5~3对应的redo日志已失效，可以被覆盖||
|5|0|起始lsn|5~4:硬盘|5~4:一致||

我们来回顾一下：

1. 为了保证宕机时数据不丢失，采用WAL，为了减少恢复的时间，使用了checkpoint，为了加快日志的写入速度使用了redo log buffer。磁盘上的redo log容量有限，在两个checkpoint之间，发现redo log快不够时，则刷新一定量的脏页，其对应范围的lsn redo log可以被覆盖（释放）。

2. 为了加快增删改查数据的速度，使用了缓冲池。缓冲池的容量有限，所以使用了lru。lru决定将某页从缓冲池中移除，该页恰好是脏页时，需要将数据同步到内存，连带更新Pages flushed up to。

各个环节环环相扣，像艺术品。

[[转]MySQL日志——Undo Redo](http://www.cnblogs.com/Bozh/archive/2013/03/18/2966494.html)中有一种非常贴切的描述：将redo log成为新数据（还未同步到磁盘）的备份儿，重做的时候好知道怎么做。将undo log称为老数据的备份儿，恢复的时候好知道怎么恢复。

[MySQL之Undo Log和Redo Log](https://blog.csdn.net/TheLudlows/article/details/78146777)Undo + Redo的设计主要考虑的是提升IO性能，将随机读写磁盘转换为顺序读写。虽说通过缓存数据，减少了写数据的IO。
但是却引入了新的IO，即写Redo Log的IO。



